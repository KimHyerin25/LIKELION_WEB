0713 머신러닝 이론 공부

<1. 머신러닝 기초용어>

1. 머신러닝으로 풀 수 있는 문제

1) 편지 봉투에 손으로 쓴 우편번호 숫자 판별하기

2) 의료 영상 이미지에 기반한 종양을 판단하기
이미지를 입력하면 종양 양성 여부 출력

3) 의심되는 신용카드 거래를 감지하기
거래내역 입력하고 부정거래 출력

4) 블로그 글의 주제 구분
많은 양 텍스트 데이터 요약하고 핵심 주제 찾기
...

* 데이터에서 지식을 추출하는 작업
* 통계학, 인공지능, 컴퓨터 과학이 얽혀 있는 연구 분야
* 비정상적인 웹 사이트 접근 탐지 --> 정상/비정상 패턴을 찾는다.

2. 데이터와 문제 이해하기
3. 용어 이해하기 - 모델, 모델링, 샘플, 데이터포인터, 특성
* 모델링 - 정보시스템 모델링) 데이터 모델링 : (데이터들을 컴퓨터 정보 구조로 변환하는 과정), 수학적 모델링(시스템 변화 예측하는 수학적 모델이 방정식으로 표현됨)
* 데이터 마이닝 : 데이터로부터 관계, 패턴, 규칙을 모형화해서 추출
    데이터 분석과 구분 -- "기계학습 이론이 적용"
    기계학습? -- 머신러닝(예측에 초점)/데이터마이닝(미처 몰랐던 속성 발견에 초점)
* 샘플 또는 데이터포인트 : 하나의 개체 또는 "행"
* 특성 ; 샘플의 속성, 즉 "열"
* 특성 추출 : 좋은 입력 데이터를 만들어내는 것 

4. 왜 파이썬인가?
* 범용 프로그래밍 언어의 장점 : 쉽다.
* 다양한 라이브러리 : 파이썬이 데이터처리 및 적재, 통계, 자연어처리, 시각화, 이미지 처리 등의 필요한 라이브러리를 가지고 있음
* 터미널, 주피터 노트북처럼 대화형 프로그래밍 가능
* 그래픽 사용자 인터페이스나 웹 서비스를 만들 수 있음

5. 라이브러리
Numpy, SciPy, pandas, matplotlib, seaborn, plotly, scikit-learn(머신러닝 라이브러리), tensorflow, keras, pytorch(딥러닝 라이브러리) 
 --머신러닝 라이브러리랑 딥러닝 라이브러리는 무슨 차이에요? : 내가 알아봐
 머신러닝은 특정한 데이터 부류를 내가 지정해 주지만 딥러닝은 무작위의 사진을 입력해주면 컴퓨터가 알아서 분류하고 답을 도출하는 식이다.

* mglearn 라이브러리 ; 이런게 있구나 식으로 알아두면 됨 - 다양한 설명을 해주기 위한 라이브러리

6. 파이썬2 vs 파이썬
2는 현재 지원하지 않음. 3를 사용함. 2020년 9월 기준 파이썬 3.8x 임

7. 머신러닝 기본 용어 이해 - 타깃과 레이블
출력될 수 있는 값인, 레이블의 범주를 클래스(class)라고 한다.
특정 포인트에 대한 출력을 레이블(label)이라고 한다.

8. iris데이터 셋
150개 sample, 5개 특성(feature)
SETOSA, VIRGINICA, VERISICOLOR
(아이리스 데이터 셋은 머신러닝 공부의 기초이므로 알아두는게 상식적이다.)

9. 훈련데이터와 테스트 데이터
* 모델의 평가 : 머신러닝 모델 만든 후, 잘 작동하는지 평가를 해야 함
* 정확한 평가 위한 데이터 나누기 :
훈련 데이터 셋(train set) : 머신러닝 모델 학습할 때 사용함
테스트 셋(test set)/ 홀드아웃 세트/ 테스트 데이터 : 머신러닝 모델 평가할 때 사용

10. 데이터에 대해 가장 먼저 할 일
머신러닝 사용해서 풀 문제인지?
필요한 정보가 누락되지 않았는지? 이상치는 없는지?
데이터 탐색을 통해 알아보기(시각화)
2개의 특성은 - 산점도
3개의 특성은 - 산점도 행렬(데이터가 많을 경운, 오랜 시간이 필요)

<머신 러닝 지도/비지도 학습 알아보기 >

01 머신러닝
* 지도학습 : 예측하려는 값(목표/target)이 존재
 - 회귀regression(수치형 변수 - 연속형)
 (knn - k최근접이웃기법, Decision Tree, 앙상블(RandomForest, GradientBoosting),신경망) -- #분류랑 거의 비슷하면서 다름
 - 분류classification(범주형 변수 - 고정됨) : 분류는 미리 정의된, 가능성이 있는 여러 클래스 레이블중 하나를 예측한다.
 (SVM, knn - 최근접이웃기법, Decision Tree, 앙상블(RandomForest, GradientBoosting),신경망, Logistic Regression)
 (이진 분류/이항분류(binary classification) : 예/아니오, 양성/음성 클래스, 
 다중 분류/다항분류(multiclass classification) : 셋 이상의 클래스로 분류)

* 비지도 학습 : target이 존재하지 않음
(Clusting, K-mean(K평균), 계층적 군집분석, 연관성 분석, DBSCA, 장바구니/서열/트랜잭션 데이터분석)
 - 군집모델(Clusting) : 레이블X,  목표변수(target)X 로 확보된 데이터의 특성을
    분석하고 서로 유사한 특징 가진 데이터끼리 그룹화한다.
 - 연관성 분석 : 장바구니 분석, 서열분석, 트랜잭션 데이터 분석
* 비정형분석 : 텍스트마이닝, 사회연결망 분석
 
* 모델이 처음보는 데이터에 대해 정확하게 예측할 수 있으면 이를 훈련 세트에서
테스트 세트로 일반화(generalization)되었다고 함.
* 가진 정보를 너무 사용해서 너무 복잡한 모델을 만드는 것을 과대적합(overfitting)이라 한다. 모델이 훈련 세트의 각 샘플에 가깝게 맞춰져서 새로운 데이터에 일반화 되기 어려울 때 발생.

* 반대로 너무 간단한 모델이 선택되는 것을 과소 적합(underfitting)라고 한다.

02 k-최근접 이웃 knn 모델 -07.13.화 수업내용

 - 분류
▶ 가장 가까운 훈련 데이터 포인트를 찾아 이를 예측에 활용한다. (분류의 경우)
▶ 새로운 데이터는 해당 거리안의 데이터가 가장 많이 있는 클래스로 분류하게 된다.(분류)
 - 회귀
▶ 가장 가까운 훈련 데이터 포인트를 찾아 이를 예측에 활용한다. (회귀의 경우)
▶ 새로운 데이터는 해당 거리안의 k개 데이터가 예측하는 목표변수의 값의 평균으로 예측하게
된다.(회귀의 경우)
▶ 이웃 간의 거리를 계산할 때 특성마다 값의 범위가 다를 경우, 범위가 작은 특성에 영향을 받는다.따라서 k-NN 알고리즘을 사용할 때는 특성들이 같은 스케일을 갖도록 정규화하는 것이 일반적이다.

https://github.com/LDJWJ/ML_Basic_Class/blob/main/part03_ml/ch02_01_01_knn_code.pdf

https://roboreport.co.kr/기계학습-훈련-데이터-구성-방법/
* stratify=y : 테스트, 훈련 데이터들의 클래스 비율들을 각각 비슷하게 유지함
(층, 계층화하다, 층을 이루다라는 뜻.. 비율을 만드는데 층층이 비율만드는 뜻으로 사용되는듯)



03 선형모델(linear model) -07.14.수
* 선형모델
- 가장 간단하고 오래된 회귀용 선형 알고리즘, 입력특성에 대한 선형함수를 만들어 예측 수행
- 선형모델은 w와 b를 학습해서 정한다.
- 특성이 하나일땐 직선 / 두개일땐 평면 / 더 높은 차원에서는 초평면
y = w1*x1 + w2*x2 + ... + wp*xp + b
y : 예측값/ xi : 특성 / wi : 기울기(가중치), 계수 / b : 편향 또는 절편

04 하이퍼 파라미터(hyperparameter)
- 모델파라미터/계수 : 머신러닝에서 알고리즘이 주어진 데이터로부터 학습하는 파라미터
- 하이퍼파라미터/매개변수 : 모델이 학습할 수 없는 사람이 직접 설정해주어야 하는 파라미터

05 선형회귀(linear regression)
- 선형회귀는 평균제곱오차(MSE)를 최소화하는 파라미터 w,b를 찾는다.
- 선형회귀는 매개변수(직접 지정하는 변수)가 없는 것이 장점이지만 모델 복잡도를 제어할 방법이 없다.
* 결정계수(R^) : scikit-learn의 score메소드에서 사용, 회귀모델에서 예측의 적합도를 측정한 것이다.
* y = 타깃값, ^y = 예측값, -y = 평균. 
 : (식) 타깃값에서 예측값을 뺀 제곱의 시네마를 타깃값에서 평균을 뺀 제곱의 시네마로 나눈 뒤 일에서 빼준다.
* 선형회귀의 과적합 해결방법 : 일반화하기 - 정규화항 사용 : MSE + regular-term(정규화 항)
선형회귀모델/오차함수


06 릿지 회귀와 랏소 회귀
* 라쏘회귀(L1) : 가중치(w)의 절댓값을 0에 가깝게, 어떤 것은 0이 되어 변수가 삭제됨
- alpha 매개변수를 이용하여 계수를 얼마나 강하게 0으로 규제할지 정한다.
- w의 절댓값을 더한
* 릿지회귀(L2) : 0에 가깝게 만들며 0이 되진 않는다.
- alpha는 덜 중요해진다. 
- w를 제곱한걸 더한


07 ElasticNet(엘라스틱넷)
 : 라쏘, 릿지를 결합한 모델, 가장 좋은 성능이지만 L1, L2규제를 위한 매개변수 두개가 필요

08 결정 트리(decision tree)
 : True, False... 쭉쭉쭉 이어나가서 답을 얻는 형태

09 분류용 선형 모델

- 선형분류기 : 선, 평면, 초평면을 사용해서 두 개의 클래스를 분류하는 분류기
- 선형 분류 알고리즘
 1) 로지스틱 회귀(Logistic Regression)
 2) 서포트 벡터 머신(support vector machine)




