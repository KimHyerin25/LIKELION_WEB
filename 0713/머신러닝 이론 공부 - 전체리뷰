머신러닝 라이브러리

scikit-learn
SciPy (20번 중에 1-2번)

*제일중요
Numpy
Matplotlib
Pandas

01 데이터 나누기
- 훈련데이터
- 테스트 데이터
나누는 이유 : 모델에 대한 평가를 위해서
75%(훈) 25%(테)로 나눔 보통 - test_size
계층적으로 - stratify

02 머신러닝 모델 만들기
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
from sklearn.ensemble import RandomForest
from sklearn.linear_model import LinearRegression
RandomForestRegressor, RandomForestClassifier

m = _____()
m.fit(입력, 출력)
pred = m.predict(새로운 데이터 입력)

03 머신러닝 모델 평가
MSE, MAE, RMSE, RMLSE ...

04 knn 모델
과대적합, 과소적합
score 함수 : 분류 - 정확도, 회귀 - 결정계수(0~1)
결정계수는 상관계수 값의 제곱과 같음

05 선형모델
y = w1 * x1 + w2 * x2 ... + b
평균제곱오차(MSE)
- 선형모델의 과대적합은 사용되는 특징이 많아질때 나타날 수 있음
(14개 -> 약 100여개 특징을 만들었을때, train 데이터 스코어점수랑 test랑 차이가 넘 많이 났음)
--> 과대적합 해결하기 위한 방법 : 릿지, 라쏘
릿지, 라쏘의 공통점 : 가중치의 절댓값을 0에 가깝게 만든다.
y = w1 * x1 + w2 * x2 ... + b
랏소 - L1 규제
릿지 - L2 규제

06 정규화
- 0~1 사이로 값의 범위를 만들어줌

06 DecisionTree

맨 위가 루트 노드, 맨 마지막이 리프 노드
노드의 개수가 몇개까지 가능한가? - 우리가 하는건 거의 이진결정트리 --> 2개 이상 가지지 않는다. 바이너리디시전트리

노드를 나누는 기준(2가지) : gini(범주형) 계수 와 entropy(범주형), +MSE(수치형 모델 예측)

depth : 깊이 (몇번 True, False를 가지를 쳤나? 그림에서는 0,1,2,3 까지 셈)
0을 가리키는 데이터와 1을 가리키는 데이터가 섞여있는데 최빈값(분류)으로 출력한다.

과대적합을 해결하기 위해 가지치기를 하는데 방법 두가지? 사전가지치기, 사후가지치기
사전가지치기는 tree가 다 만들기 전에 max_depth, leaf_node 개수를 제한하고
사후가지치기는 tree가 다 만들어진 후에 terminal node를 결합

특성 중요도 : 전체 특성의 중요도를 합치면 1이 된다. 특성 중요도는 0과 1사이의 숫자고, 이 나무를 만드는데에 있어서 중간 중간 변수를 택해서 분리를 시키지. 146보다 커?아니. 맞아. 이런식으로. 근데 이 변수들의 중요도를 보여주는게 feature importance 인거고 우리는 이 feature가 나무에서 얼마나 중요하게 사용됐는지 알수 잇음, 이게 크다고 피쳐가 중요하다라고도 근데 말할 순 없음... 완전 동일하진 않다.


랜덤포레스트 : n개의 모델을 만드는데, 모델이 과대적합이 될 수 있는 가능성을 여러개 만들어서 가능성을 좀 줄여주니까 의사결정트리보다 성능이 좋음.
각각 약간씩 다른 모델들이 만들어짐. --> 부트스트랩샘플링 : 중복허용, feature 사용개수를 제한
범주형은 - 최빈값, 수치형은 - 평균값으로 예측함

https://www.kaggle.com/chocozzz/house-price-prediction-eda-updated-2019-03-12


랜덤포레스트는 각각의 여러개 모델을 만들때 서로서로영향을 주지 않는다.
그래디언트 부스팅은 사용하지않는 변수들 조차도 사용해보자, 그다음, 그다음, 하다보면 나중에는
사용되지 않는 피쳐까지 사용하게 되면서 세밀한 부분까지 들어가고, 랜덤포레스트의 단점을 보완해주는 느낌(XGB, LGBMㄴ)

